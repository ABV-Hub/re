{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование обводнённости скважин с помощью методов машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2.3 final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем исходные данные на 01.06.2018 из экселя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/ps_owc/df.xlsx'\n",
    "df = pd.read_excel(data_path, sheet_name='v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем местоположение скважин - строим карту забоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot(kind='scatter', x='x', y='y')\n",
    "df[['x','y','Well']].apply(lambda row: ax.text(*row),axis=1);\n",
    "rcParams['figure.figsize'] = [11, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конструирование признаков (feature engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитываем матрицу евклидовых расстояний между скважинами из их координат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = pd.DataFrame(euclidean_distances(df[['x', 'y']]))\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлекаем список имён скважин. Присваеваем имена скважин колонкам матрицы расстояний. Таким образом именуем столбцы с расстояними именами скважин, расстояния до которых вычислены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_names = df['Well']\n",
    "distance.columns = well_names\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем датасет парметров работы скважин с матрицей расстояний между скважинами. Таким образом в датасет добавляем N-столбцов, где N - количество скважин в датасете. Т.е. конструируем N новых признаков (feature engineering) где параметр удалённости является весом (вкладом/влиянием) скважин друг на друга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distance = pd.concat([df.drop(['x', 'y'], axis=1), distance], axis=1)\n",
    "df_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тренировочный дата сет, удаляя из него скважины, выбранные для теста и прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_1 = df_distance.drop([12, 13, 14, 15], axis=0)\n",
    "df_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тестовый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_1 = df_distance.loc[[12, 13]]\n",
    "df_test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тренировочный DataFrame признаков X_1. Удаляем категорийный признак (имя скважины) и предсказываемое значение wct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = df_train_1.drop(['Well', 'wct'], axis=1)\n",
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тренировочный вектор целевых значений y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = df_train_1['wct']\n",
    "y_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тестовый вектор целевых значений y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1 = df_test_1['wct']\n",
    "y_test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Создаём скейлер для масштабирования данных\n",
    "- обучаем скейлер на тренировочных данных и масштабируем их\n",
    "- масштабируем тестовые данные на обученном скейлере\n",
    "- создаём модель LinearRegression / RandomForestRegressor\n",
    "- тренируем модель\n",
    "- рассчитываем обводнённость по тестовой выборке\n",
    "- рассчитываем обводнённость по тренировочной выборке\n",
    "- оцениваем качество модели: считаем коэффициенты R^2 по тестовым и тренировочным выборкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_1 = scaler.fit_transform(x_1)\n",
    "\n",
    "x_test_1 = scaler.transform(df_test_1.drop(['Well', 'wct'], axis=1))\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, max_depth=14)\n",
    "model.fit(x_train_1, y_1)\n",
    "\n",
    "y_pred_train_1 = model.predict(x_train_1)\n",
    "y_pred_1 = model.predict(x_test_1)\n",
    "\n",
    "print('Predicted values from train data:')\n",
    "r2_train = r2(y_1, y_pred_train_1)\n",
    "mae_train = mae(y_1, y_pred_train_1)\n",
    "mse_train = mse(y_1, y_pred_train_1)\n",
    "print(f'R2 train: {r2_train.round(4)}')\n",
    "print(f'MAE train: {mae_train.round(4)}')\n",
    "print(f'MSE train: {mse_train.round(4)}')\n",
    "\n",
    "print('Predicted values from test data (blind test / validation, the model has not seen this data):')\n",
    "r2_test = r2(y_test_1, y_pred_1)\n",
    "mae_test = mae(y_test_1, y_pred_1)\n",
    "mse_test = mse(y_test_1, y_pred_1)\n",
    "print(f'R2 test: {r2_test.round(4)}')\n",
    "print(f'MAE test: {mae_test.round(4)}')\n",
    "print(f'MSE test: {mse_test.round(4)}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 метрика на тренировочной метрике превышает R2 на тестовой на 7%, что что означает низкую степень переобучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним предсказанную обводнённсть с фактической на тестовой выборке, которая не использовалась при обучении модели (blind test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame({'Well': df_test_1['Well'], \n",
    "                          'wct predicted, %': y_pred_1.round(1), \n",
    "                          'wct actual, %': y_test_1.round(1),\n",
    "                          'difference': (y_pred_1 - y_test_1).round(1)})\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним предсказанную обводнённость с фактической на тренировочной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = pd.DataFrame({'Well': df_train_1['Well'], \n",
    "                           'wct predicted, %': y_pred_train_1.round(1), \n",
    "                           'wct actual, %': y_1.round(1),\n",
    "                           'difference': (y_pred_train_1 - y_1).round(1)})\n",
    "df_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели на всех доступных данных (train + test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тренировочный дата сет, удаляя из него скважины, выбранные для прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_2 = df_distance.drop([14, 15], axis=0)\n",
    "df_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём датасет для прогнозирования из скважин, удалённых на предыдущем шаге.\n",
    "\n",
    "Предсказываемый параметр WCT (обводнённсть) сейчас = NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fc = df_distance.loc[[14, 15]]\n",
    "df_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующей ячейке представлена возможность смены кровли Ливенского горизонта в точке вскрытия скважины. Опция добавлена для ручного изменения параметра, чтобы оценить чувствительность модели к изменению параметра.\n",
    "\n",
    "Чувствительность модели к параметру кровли структуры (принимаем, что кровля = верху интервала перфорации/открытого ствола) низкая. Изменение кровли пласта выше разумного предела пределах (>100 м) не приводит к значимому изменению обводённсти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходный параметр Top perf = -2314 м а.о.\n",
    "# df_fc.at[15,'Top perf']= -2300\n",
    "# df_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тренировочный DataFrame признаков x_2. Удаляем категорийный признак (имя скважины) и предсказываемое значение wct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = df_train_2.drop(['Well', 'wct'], axis=1)\n",
    "x_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём тренировочный вектор целевых значений y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = df_train_2['wct']\n",
    "y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_2 = scaler.fit_transform(x_2)\n",
    "\n",
    "x_fc = scaler.transform(df_fc.drop(['Well', 'wct'], axis=1))\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, max_depth=14)\n",
    "model.fit(x_train_2, y_2)\n",
    "\n",
    "y_pred_train_2 = model.predict(x_train_2)\n",
    "y_fc = model.predict(x_fc)\n",
    "\n",
    "print('Predicted values from train data:')\n",
    "r2_train = r2(y_2, y_pred_train_2)\n",
    "mae_train = mae(y_2, y_pred_train_2)\n",
    "mse_train = mse(y_2, y_pred_train_2)\n",
    "print(f'R2 train: {r2_train.round(4)}')\n",
    "print(f'MAE train: {mae_train.round(4)}')\n",
    "print(f'MSE train: {mse_train.round(4)}')\n",
    "\n",
    "print('Forecasted values could be compared with real data!')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 повысилось. Или модель переобучилась или большее количество данных помогло точнее настроить модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним предсказанную обводнённость с фактической на тренировочной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = pd.DataFrame({'Well': df_train_2['Well'], \n",
    "                           'wct predicted, %': y_pred_train_2.round(1), \n",
    "                           'wct actual, %': y_2.round(1),\n",
    "                           'difference': (y_pred_train_2 - y_2).round(1)})\n",
    "df_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываемя обводнённость по боковым стволам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame({'Well': df_test_1['Well'], \n",
    "                          'wct predicted, %': y_pred_1.round(1), \n",
    "                          'wct actual, %': y_test_1.round(1),\n",
    "                          'difference': (y_pred_1 - y_test_1).round(1)})\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим список признаков в порядке убыввания их важности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature_name'] = x_2.columns.tolist()\n",
    "feature_importances['importance'] = model.feature_importances_\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим диаграмму важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(feature_importances, \n",
    "             x=feature_importances['importance'], \n",
    "             y=feature_importances['feature_name'], \n",
    "             title=\"Feature importances\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнительный график реальных и предсказанных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=y_pred_train_2, y=y_2, title=\"True vs Predicted values\",\n",
    "                 text=df_train_2['Well'], width=850, height=800)\n",
    "fig.add_trace(go.Scatter(x=[0,100], y=[0,100], mode='lines', name='True=Predicted',\n",
    "                         line = dict(color='red', width=1, dash='dash')))\n",
    "fig.update_xaxes(title_text='Predicted')\n",
    "fig.update_yaxes(title_text='True')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
