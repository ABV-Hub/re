{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well water cut calculation using Machine Learning\n",
    "#### Alexander Kalinichenko\n",
    "\n",
    "This notebook demonstrates how to train a machine learning algorithm to predict water cut (WCT) of oil production wells.\n",
    "The exercise is based on data of a field in Russia, Volga-Ural basin.\n",
    "\n",
    "_Add some info about field..._\n",
    "\n",
    "The dataset was created from observed production data from 70 wells which was combined with other well bore data such as bottom location, perforation interval, well bore type, well operation duration etc. This data uses to train Random Forresr Regression to predict water cut of producing wells or planned side-tracks. The sklearn.ensemble module was used in this exercise. The [enseble methods](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble) includes ensemble-based methods for classification, regression and anomaly detection from [scikit-learn Python library](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. A random forest regresor was choosen because this is simple, easy undenstandable without over-fitting algorithm.\n",
    "\n",
    "First we will [explore the dataset](#Exploring-the-dataset).  We will load the training data from 70 wells, and take a look at what we have to work with.  We will plot the location data , and create cross plots to look at the variation within the data.  \n",
    "\n",
    ". . .\n",
    "\n",
    "## well locations in the dataset converted to dictances between wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Глобальная задача:**\n",
    "- оценить перспективу бурения дополнительных сайдтреков\n",
    "\n",
    "Дополнительные задачи:\n",
    "- предсказать обводнённость\n",
    "- предсказать дополнительную добычу\n",
    "- предсказать ВНК"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### кроме R2 добавить SMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import datetime\n",
    "#from datetime import datetime, date\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "#import math\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "#from sklearn.model_selection import KFold, GridSearchCV\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.neighbors import DistanceMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data at exact date (2018-06-01 - last available production data for all wells of the field). Drop unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/df.xlsx'\n",
    "df = pd.read_excel(data_path, sheet_name='prod')\n",
    "df = df.drop(['Pres'], axis=1)\n",
    "df_2018_06_01 = df.loc[df_train['Date'] == '2018-06-01']\n",
    "df_2018_06_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that data loaded right. Plot well location map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = df_2018_06_01.plot(kind='scatter', x='x', y='y')\n",
    "df_2018_06_01[['x','y','Well']].apply(lambda row: ax.text(*row),axis=1);\n",
    "rcParams['figure.figsize'] = [11, 8]\n",
    "#plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of distance between wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "loc = pd.DataFrame(dist.pairwise(df_train[['x','y']].to_numpy()),\n",
    "             columns=df_train.Well.unique(), index=df_train.Well.unique())\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = df_test.drop(['Well', 'wct'], axis=1)\n",
    "# y_test = df_test['wct']\n",
    "# x_test\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_prep = df_train.drop(['Well', 'wct', 'x', 'y'], axis=1)\n",
    "# y = df_train['wct']\n",
    "x = pd.concat([df_train_prep, loc], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1, random_state=100)\n",
    "mc = pca.fit_transform(df_train[['x', 'y']])\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.drop(['Well', 'wct', 'x', 'y'], axis=1)\n",
    "x['loc'] = mc\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1, random_state=100)\n",
    "mc_test = pca.fit_transform(df_test[['x', 'y']])\n",
    "mc_test\n",
    "\n",
    "x_test = df_test.drop(['Well', 'wct', 'x', 'y'], axis=1)\n",
    "x_test['loc'] = mc_test\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x)\n",
    "\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, max_depth=14)\n",
    "model.fit(x_train, y)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "r2_train = r2(y, y_pred_train)\n",
    "print(f'R2 train: {r2_train.round(4)}')\n",
    "\n",
    "r2_test = r2(y_test, y_pred)\n",
    "print(f'R2 test: {r2_train.round(4)}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame({'Well': df_test['Well'], \n",
    "                          'wct predicted, %': y_pred.round(1), \n",
    "                          'wct actual, %': y_test.round(1)})\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = pd.DataFrame({'Well': df_train['Well'], \n",
    "                           'wct predicted, %': y_pred_train.round(1), \n",
    "                           'wct actual, %': y.round(1)})\n",
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['importance'] = model.feature_importances_\n",
    "feature_importances['feature_name'] = x.columns.tolist()\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = feature_importances.sort_values(by='importance', ascending=True)\n",
    "height = feature_importances['importance']\n",
    "bars = feature_importances['feature_name']\n",
    "y_pos = np.arange(len(bars))\n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, height)\n",
    " # Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(true_values, pred_values):\n",
    "    print(\"R2:\\t\" + str(round(r2(true_values, pred_values), 3)) + \"\\n\" +\n",
    "          \"MAE:\\t\" + str(round(mae(true_values, pred_values), 0)) + \"\\n\" +\n",
    "          \"MSE:\\t\" + str(round(mse(true_values, pred_values), 0))) \n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=pred_values, y=true_values, s=1)\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('True vs Predicted values')\n",
    "    plt.ylim(0, 105)\n",
    "    plt.xlim(0, 105)\n",
    "    plt.show()\n",
    "\n",
    "evaluate_preds(y_pred_train.flatten(), y.values.flatten())\n",
    "evaluate_preds(y_pred.flatten(), y_test.values.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
