{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OWC estimator v2\n",
    "## well locations processed as is without any transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавить MVA и кроссвалидацию\n",
    "\n",
    "blind test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "\n",
    "data_path = '../data/ps_owc/df.xlsx'\n",
    "df_train = pd.read_excel(data_path, sheet_name='train2')\n",
    "df_test = pd.read_excel(data_path, sheet_name='test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка разбита на тренировочный и тестовый сеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тестовой выборке удаляем имя скважины и целевой (предсказываемый) признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.drop(['Well', 'wct'], axis=1)\n",
    "y_test = df_test['wct']\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем имя скважины и целевой (предсказываемый) признак в тренировочной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.drop(['Well', 'wct'], axis=1)\n",
    "y = df_train['wct']\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём скейлер для масштабирования данных\n",
    "\n",
    "обучаем скейлер на тренировочных данных и масштабируем их\n",
    "\n",
    "масштабируем тестовые данные на обученном скейлере\n",
    "\n",
    "создаём модель LinearRegression / RandomForestRegressor\n",
    "\n",
    "тренируем модель\n",
    "\n",
    "рассчитываем обводнённость по тестовой выборке\n",
    "\n",
    "рассчитываем обводнённость по тренировочной выборке\n",
    "\n",
    "оцениваем качество модели: считаем коэффициенты R^2 по тестовым и тренировочным выборкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x)\n",
    "\n",
    "x_test = scaler.transform(df_test.drop(['Well', 'wct'], axis=1))\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, max_depth=14)\n",
    "model.fit(x_train, y)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "r2_train = r2(y, y_pred_train)\n",
    "print(f'R2 train: {r2_train.round(4)}')\n",
    "\n",
    "r2_test = r2(y_test, y_pred)\n",
    "print(f'R2 test: {r2_train.round(4)}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_test = pd.DataFrame({'Well': df_test['Well'], \n",
    "                          'wct predicted, %': y_pred.round(1), \n",
    "                          'wct actual, %': y_test.round(1)})\n",
    "df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = pd.DataFrame({'Well': df_train['Well'], \n",
    "                           'wct predicted, %': y_pred_train.round(1), \n",
    "                           'wct actual, %': y.round(1)})\n",
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['importance'] = model.feature_importances_\n",
    "feature_importances['feature_name'] = x.columns.tolist()\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = feature_importances.sort_values(by='importance', ascending=True)\n",
    "height = feature_importances['importance']\n",
    "bars = feature_importances['feature_name']\n",
    "y_pos = np.arange(len(bars))\n",
    "# Create horizontal bars\n",
    "plt.barh(y_pos, height)\n",
    " # Create names on the y-axis\n",
    "plt.yticks(y_pos, bars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(true_values, pred_values):\n",
    "    print(\"R2:\\t\" + str(round(r2(true_values, pred_values), 3)) + \"\\n\" +\n",
    "          \"MAE:\\t\" + str(round(mae(true_values, pred_values), 0)) + \"\\n\" +\n",
    "          \"MSE:\\t\" + str(round(mse(true_values, pred_values), 0))) \n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=pred_values, y=true_values, s=20)\n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('True vs Predicted values')\n",
    "    plt.ylim(0, 105)\n",
    "    plt.xlim(0, 105)\n",
    "    plt.show()\n",
    "\n",
    "evaluate_preds(y.values.flatten(), y_pred_train.flatten())\n",
    "evaluate_preds(y_test.values.flatten(), y_pred.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
